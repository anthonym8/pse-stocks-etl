name: Delta Lake Sync via Spark

on:
  workflow_dispatch:


env:
  DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
  DOCKERHUB_REPOSITORY: ${{ secrets.DOCKERHUB_REPOSITORY }}


jobs:

  sync-spark-deltalake:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Create credentials key file
      env:
        GCP_CREDENTIALS_JSON: '${{ secrets.PROD_GCP_CREDENTIALS_JSON }}'
      run: |
        mkdir credentials 
        printf '%s ' $GCP_CREDENTIALS_JSON >| credentials/keyfile.json;

    - name: Build Docker image
      run: docker build . --file src/db/delta_spark/Dockerfile-spark --tag pse-stocks-etl-spark

    - name: Run sync job
      env:
        GCP_CREDENTIALS_FILE: ${{ secrets.GCP_CREDENTIALS_FILE }}
        DELTA_TABLE_PATH_PREFIX: ${{ secrets.DELTA_TABLE_PATH_PREFIX }}
      run: |
        docker run \
          -e GCP_CREDENTIALS_FILE=$GCP_CREDENTIALS_FILE \
          -e DELTA_TABLE_PATH_PREFIX=$DELTA_TABLE_PATH_PREFIX \
          -v $PWD/credentials:/pse-stocks-etl/credentials \
          pse-stocks-etl-spark